{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00def900",
   "metadata": {},
   "source": [
    "# Character-Level Text Generation Using RNN\n",
    "\n",
    "**Objective:**\n",
    "The goal of this project is to build a character-level Recurrent Neural Network (RNN) capable of generating text in the style of William Shakespeare. The model is trained on a dataset of Shakespeare's works, learning to predict the next character in a sequence, and can be used to generate new, coherent text sequences.\n",
    "\n",
    "**Dataset:**\n",
    "The dataset consists of the complete works of Shakespeare, obtained from a public domain source. It is loaded and processed into a format suitable for training a character-level RNN.\n",
    "\n",
    "**Methodology:**\n",
    "1. **Data Preprocessing:**\n",
    "   - The text is vectorized by mapping each unique character to an integer index.\n",
    "   - Input sequences of fixed length (e.g., 100 characters) are created, with each sequence paired with the corresponding target sequence (i.e., the next character in the text).\n",
    "\n",
    "2. **Model Architecture:**\n",
    "   - An embedding layer is used to convert character indices into dense vectors of a fixed size.\n",
    "   - A GRU (Gated Recurrent Unit) layer with 1024 units is employed to capture temporal dependencies in the sequence data.\n",
    "   - The output layer is a Dense layer that outputs logits corresponding to the probability distribution over all possible characters.\n",
    "\n",
    "3. **Training:**\n",
    "   - The model is trained using categorical cross-entropy loss, with the Adam optimizer.\n",
    "   - Checkpoints are saved after each epoch to allow for the resumption of training and model evaluation at various stages.\n",
    "\n",
    "4. **Text Generation:**\n",
    "   - After training, the model is used to generate text by predicting the next character in a sequence given an initial input string.\n",
    "   - The generation process involves sampling from the probability distribution of the next character, iteratively producing a text sequence.\n",
    "\n",
    "**Results:**\n",
    "The trained model can generate text that mimics the style of Shakespeare, producing coherent and contextually relevant passages. The quality of the generated text improves with more epochs of training, though it may still contain some non-sensical or repetitive phrases typical of character-level models.\n",
    "\n",
    "**Conclusion:**\n",
    "This project demonstrates the effectiveness of RNNs in sequence modeling tasks such as text generation. While the generated text captures the essence of Shakespeare's style, further improvements could involve using more advanced architectures like LSTM or Transformer models and experimenting with hyperparameters or training techniques to enhance the coherence and creativity of the generated text.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76916c09",
   "metadata": {},
   "source": [
    "### GRU-Based RNN Architecture for Character-Level Text Generation\n",
    "\n",
    "This image represents the architecture of a Recurrent Neural Network (RNN) using Gated Recurrent Units (GRUs) for character-level text generation. Here's a breakdown of the components:\n",
    "\n",
    "1. **Input Characters (`Input Char`)**:\n",
    "   - The model receives sequences of characters as input. Each character is represented by an index in a vocabulary.\n",
    "\n",
    "2. **Embedding Layer**:\n",
    "   - The input characters are passed through an embedding layer. This layer converts the character indices into dense vectors of a fixed size (`EMBEDDING_SIZE`). The embeddings capture semantic meaning and are learnable parameters of the model.\n",
    "\n",
    "3. **GRU Layers**:\n",
    "   - The embeddings are then passed through a series of GRU layers. GRUs are a type of RNN that are designed to handle sequential data and can maintain information across time steps. Each GRU cell takes the current embedding and the previous hidden state (`State Before`) to produce a new hidden state (`GRU Output`) and update the state (`State After`).\n",
    "   - The GRU outputs are sequences of hidden states, each corresponding to a time step in the input sequence.\n",
    "\n",
    "4. **Dense Layer**:\n",
    "   - The outputs from the GRU layers are then passed through a dense layer. This layer is fully connected and transforms the GRU outputs into logits. The logits are raw prediction scores for each character in the vocabulary.\n",
    "\n",
    "5. **Logits**:\n",
    "   - Finally, the logits are used to predict the next character in the sequence. The model will generate a probability distribution over all possible characters, from which the next character is sampled or selected.\n",
    "\n",
    "6. **State Before/After**:\n",
    "   - The state before represents the hidden state that is passed into the GRU cell, while the state after represents the updated hidden state after processing the input character. This state carries information from one time step to the next, allowing the model to maintain context.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04074f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 1115394 characters\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,938,304</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">66,625</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_4 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │        \u001b[38;5;34m16,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_2 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │     \u001b[38;5;34m3,938,304\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m)       │        \u001b[38;5;34m66,625\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,021,569</span> (15.34 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,021,569\u001b[0m (15.34 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,021,569</span> (15.34 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,021,569\u001b[0m (15.34 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 65) # (batch_size, sequence_length, vocab_size)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-03 12:41:39.449504: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Download the Shakespeare dataset\n",
    "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
    "\n",
    "# Read the dataset\n",
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "print(f'Length of text: {len(text)} characters')\n",
    "\n",
    "# View the first 250 characters in the text\n",
    "print(text[:250])\n",
    "\n",
    "# Create character index\n",
    "vocab = sorted(set(text))\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "# Text vectorization\n",
    "text_as_int = np.array([char2idx[c] for c in text])\n",
    "\n",
    "# Set training parameters\n",
    "seq_length = 100\n",
    "examples_per_epoch = len(text) // seq_length\n",
    "\n",
    "# Create input and output samples\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)\n",
    "\n",
    "# Batching datasets\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 256\n",
    "rnn_units = 1024\n",
    "\n",
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim, input_shape=(None,)),\n",
    "        tf.keras.layers.GRU(rnn_units, return_sequences=True, recurrent_initializer='glorot_uniform'), \n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model(\n",
    "    vocab_size=len(vocab),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Define the loss function\n",
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "model.compile(optimizer='adam', loss=loss)\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Check the shape of the input sample\n",
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n",
    "\n",
    "# Configure training checkpoints\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}.weights.h5\")  # Add the end of .weights.h5\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b6b40f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 685ms/step - loss: 3.0782\n",
      "Epoch 2/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 701ms/step - loss: 1.9123\n",
      "Epoch 3/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 706ms/step - loss: 1.6313\n",
      "Epoch 4/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 733ms/step - loss: 1.4800\n",
      "Epoch 5/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 746ms/step - loss: 1.3934\n",
      "Epoch 6/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 747ms/step - loss: 1.3233\n",
      "Epoch 7/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 742ms/step - loss: 1.2796\n",
      "Epoch 8/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 730ms/step - loss: 1.2328\n",
      "Epoch 9/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 730ms/step - loss: 1.1872\n",
      "Epoch 10/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 745ms/step - loss: 1.1451\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Train the model and record the losses\n",
    "EPOCHS = 10\n",
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])\n",
    "\n",
    "# Visualize training losses\n",
    "plt.plot(history.history['loss'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2555331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ckpt_7.weights.h5', 'ckpt_2.weights.h5', 'ckpt_8.weights.h5', 'ckpt_5.weights.h5', 'ckpt_3.weights.h5', 'ckpt_6.weights.h5', 'ckpt_1.weights.h5', 'ckpt_10.weights.h5', 'ckpt_9.weights.h5', 'ckpt_4.weights.h5']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(os.listdir(checkpoint_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3770269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shakespear than maill amathyomer the THere mowitheve d gusth Lewh mowan as s blil aver lmy igl brdyou hineron: thavires yon kelarstofune.\n",
      "Mar ouryonyspotryo\n",
      "APdinus iomy me tior MI he I iexout id d cugatheere-prinLE\n",
      "UPDy,\n",
      "K:\n",
      "Hapr iver:\n",
      "Tige br wano te?\n",
      "HOR3\n",
      "ALAn'\n",
      "TIO themy whinew, ke.\n",
      "NG.\n",
      "F g boro:\n",
      "SChamo hallod mishe o hy chergho blevene futher y s toungopounevitreas he warat oo smofuriny:\n",
      "ARE thesoutas br IChathin dengesiure? E owit pry:\n",
      "CKeno,\n",
      "CAWe he yow f.\n",
      "AUT apes, as, bo coug aligr hed Yodukee Ore, s aiswak.\n",
      "Tor:\n",
      "ERIOWhour'd athe\n",
      "BAmoulldille t\n",
      "Burs s lerts Be\n",
      "Ty, p, ande RUpinfot R3 or:\n",
      "Be hapualy thal y sh wo I ore?\n",
      "ANINRIt, yo t me:\n",
      "Wh ghincoureprt booreranel winorat d y,\n",
      "G untiblin ufabt!\n",
      "Houk't urdasomyountor arar.\n",
      "TBRCAtht ng mer horshe I w'e\n",
      "Anchokn al$alod memetw, ce brailay wad ilI I Lughesc.\n",
      "RO:\n",
      "D\n",
      "\n",
      "An tacove blds w, hthyomeve wiopllbonod, ten wis tia:\n",
      "TZallut bes, hing s mared RCK: fowTo g:\n",
      "A ORDO uthouca dechape abel this ave g t I.\n",
      "TUS:\n",
      "Anbemedourealin:\n",
      "LA:\n",
      "RISce taly.\n",
      "Fod, wa\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from IPython.display import clear_output, display\n",
    "\n",
    "# Text generation functions\n",
    "def generate_text(model, start_string):\n",
    "    num_generate = 1000\n",
    "\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    text_generated = []\n",
    "\n",
    "    temperature = 1.0\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
    "\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "    \n",
    "        display(start_string + ''.join(text_generated))\n",
    "        clear_output(wait=True)\n",
    "        time.sleep(0.05)\n",
    "\n",
    "    return (start_string + ''.join(text_generated))\n",
    "\n",
    "\n",
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "# Select the latest checkpoint file path\n",
    "checkpoint_path = os.path.join(checkpoint_dir, 'ckpt_10.weights.h5')\n",
    "\n",
    "# Load checkpoint weights\n",
    "model.load_weights(checkpoint_path)\n",
    "\n",
    "# Generate and dynamically display text\n",
    "generated_text = generate_text(model, start_string=u\"Shakespear\")\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dce161a",
   "metadata": {},
   "source": [
    "### Analysis of the Generated Text\n",
    "\n",
    "\n",
    "1. **Presence of English-like Words**:\n",
    "   - The generated text contains fragments and words that resemble English, such as \"Shakespear,\" \"THere,\" \"Mar,\" and \"IChathin.\" This indicates that the model has learned some patterns from the training data and is able to produce character sequences that vaguely resemble English words.\n",
    "   - However, these words often appear incomplete or nonsensical, suggesting that the model struggles to fully capture the correct spelling and structure of words.\n",
    "\n",
    "2. **Randomness and Lack of Coherence**:\n",
    "   - The text lacks coherence and meaningful content. The sequence of characters and words does not form any meaningful sentences or phrases, and there are many instances of random, unstructured character combinations like \"thavires yon kelarstofune\" and \"SChamo hallod mishe.\"\n",
    "   - This randomness is partly due to the model's attempt to balance creativity and coherence, but it seems the model is leaning too much towards randomness in this case.\n",
    "\n",
    "3. **Repetition of Character Combinations**:\n",
    "   - There are instances where certain character combinations, like \"iomy,\" \"kelar,\" and \"warat,\" are repeated or appear similar in structure. This might indicate that the model has learned some recurring patterns from the data but is overfitting to those patterns without understanding their context or meaning.\n",
    "\n",
    "4. **Symbols and Numbers**:\n",
    "   - The presence of symbols like \":\", \"3\", and capital letters in seemingly random places suggests that the model is still learning where and how to appropriately use punctuation and capitalization. It also indicates that the model might be incorporating rare or less frequent patterns that it encountered during training.\n",
    "\n",
    "5. **Structural Issues**:\n",
    "   - The text generated does not follow any recognizable structure of prose or verse, which is particularly noticeable given that Shakespeare's works often follow strict metrical patterns (like iambic pentameter). The generated text lacks this rhythmic structure, indicating that the model has not yet learned these complex linguistic features.\n",
    "\n",
    "### Reasons for These Results:\n",
    "\n",
    "1. **Model Complexity**:\n",
    "   - The GRU-based model, while effective at capturing some sequential patterns, may not be complex enough to capture the intricacies of English grammar, syntax, and poetic structure. More advanced models, such as those based on LSTM or Transformer architectures, might perform better.\n",
    "\n",
    "2. **Training Duration**:\n",
    "   - The model may not have been trained for long enough or on a sufficiently large dataset. More extensive training with more data could help the model learn better representations of the language.\n",
    "\n",
    "3. **Temperature Setting**:\n",
    "   - The temperature setting was 1.0, which allows for high variability in predictions. Lowering the temperature might result in more coherent and predictable outputs, though at the risk of reducing creativity.\n",
    "\n",
    "### Recommendations:\n",
    "\n",
    "1. **Further Training**:\n",
    "   - Consider training the model for additional epochs to allow it more time to learn from the data. This could improve the coherence and quality of the generated text.\n",
    "\n",
    "2. **Experiment with Temperature**:\n",
    "   - Adjust the temperature parameter to lower values (e.g., 0.7 or 0.5) during text generation. This might help produce more coherent and meaningful text by reducing randomness.\n",
    "\n",
    "3. **Model Architecture**:\n",
    "   - Experiment with more complex architectures like LSTM or Transformer models, which may better capture the long-range dependencies and sophisticated structures present in Shakespeare's and Poe's writings.\n",
    "\n",
    "4. **Fine-tuning**:\n",
    "   - Consider fine-tuning the model on specific subsets of data (e.g., only sonnets or only prose) to see if it can better capture and replicate those specific styles.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f3149d",
   "metadata": {},
   "source": [
    "\n",
    "### Advantages of GPT-2: \n",
    "\n",
    "- **Better Context Handling**: GPT-2 handles longer-range dependencies in text better than LSTMs.\n",
    "- **Advanced Sampling Techniques**: GPT-2 allows for sophisticated sampling techniques like top-k and top-p, which improve the diversity and quality of generated text.\n",
    "- **State-of-the-Art Performance**: GPT-2 is a state-of-the-art model for natural language generation, providing better fluency and coherence in the generated text.\n",
    "\n",
    "This approach should give you a significant improvement over the previous LSTM-based model in terms of the quality and coherence of the generated text. Let me know if you need further customization or explanations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7cfcaba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuyao/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shakespeare is a great writer, but he has a very limited background in literary scholarship. He was a graduate of the University of Chicago, where he was a graduate student of the English Language Arts Department. He is also a member of the Board of Trustees of the National Academy of Sciences.\n",
      "\n",
      "In his recent book The Dark Side of the Mind, he writes about his experiences as a teenager and his attempt to escape the darkness of his past. He writes: \"I was a little too young to have grown up in a world where there was a lot of darkness. I was young enough to feel ashamed of myself for not knowing the truth. I also felt ashamed for having had the privilege of having met people I really didn't know. I don't know what I will have to go through. I will have to find out what I can do to help others.\"\n",
      "\n",
      "His story is told in his own words.\n",
      "\n",
      "\"I had a little bit of an early awakening when\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Load pre-trained GPT-2 model and tokenizer\n",
    "model_name = \"gpt2\"  # You can also use \"gpt2-medium\", \"gpt2-large\", or \"gpt2-xl\" for larger models\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "def generate_text_gpt2(start_string, max_length=100, temperature=1.0, num_return_sequences=1):\n",
    "    input_ids = tokenizer.encode(start_string, return_tensors='pt')\n",
    "\n",
    "    # Generate text\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        max_length=max_length,\n",
    "        temperature=temperature,\n",
    "        num_return_sequences=num_return_sequences,\n",
    "        do_sample=True,  # Enable sampling to generate diverse results\n",
    "        top_k=50,  # Use top-k sampling\n",
    "        top_p=0.95  # Use top-p (nucleus) sampling\n",
    "    )\n",
    "\n",
    "    generated_texts = [tokenizer.decode(out, skip_special_tokens=True) for out in output]\n",
    "    return generated_texts\n",
    "\n",
    "# Example usage\n",
    "start_string = \"Shakespeare\"\n",
    "generated_text = generate_text_gpt2(start_string, max_length=200, temperature=0.7, num_return_sequences=1)\n",
    "print(generated_text[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04642f04",
   "metadata": {},
   "source": [
    "The generated text demonstrates the capabilities and limitations of the GPT-2 model in generating coherent and contextually relevant text. H\n",
    "\n",
    "\n",
    "### Strengths:\n",
    "1. **Fluency and Coherence**:\n",
    "   - The text is quite fluent and maintains grammatical correctness throughout. The sentences flow logically from one to the next, which is a strong point of the GPT-2 model.\n",
    "   \n",
    "2. **Contextual Continuity**:\n",
    "   - The model successfully picks up on the cue provided by \"Shakespeare\" and attempts to generate text that might fit in a discussion about a person named Shakespeare. It introduces biographical elements and even a reference to an academic background, which, while not historically accurate, makes sense in the context of the generated narrative.\n",
    "\n",
    "3. **Creative Expansion**:\n",
    "   - GPT-2 expands on the prompt by creating a fictional scenario where \"Shakespeare\" is portrayed as a graduate student at the University of Chicago and a member of the Board of Trustees of the National Academy of Sciences. This demonstrates the model’s ability to create plausible-sounding but entirely fictional content.\n",
    "\n",
    "### Limitations:\n",
    "1. **Factual Inaccuracy**:\n",
    "   - The generated text contains several factual inaccuracies. For instance, it suggests that Shakespeare was a graduate of the University of Chicago and a member of the Board of Trustees of the National Academy of Sciences—neither of which is true. This reflects the model’s lack of grounding in historical facts, as it primarily focuses on generating coherent text rather than accurate information.\n",
    "\n",
    "2. **Inconsistent Tone**:\n",
    "   - The tone shifts slightly when the model introduces the idea of \"The Dark Side of the Mind\" and discusses personal experiences, which doesn't align with the historical Shakespeare. This indicates that the model is blending various contexts that it has learned from, rather than sticking to a consistent tone or theme.\n",
    "\n",
    "3. **Repetitive Ideas**:\n",
    "   - There’s a degree of repetition in the ideas presented, particularly around themes of shame and darkness. This can happen with GPT-2 when it tries to extend a theme but doesn't have enough context to introduce new ideas.\n",
    "\n",
    "4. **Lack of Depth**:\n",
    "   - While the model generates text that is surface-level coherent, it lacks depth and fails to provide meaningful or insightful commentary on Shakespeare or his works. The text generated is generic and does not delve into literary analysis or critical thought, which might be expected in a scholarly discussion about Shakespeare.\n",
    "\n",
    "### Conclusion:\n",
    "\n",
    "The generated text showcases GPT-2's strength in creating fluent and contextually plausible text, but it also highlights its limitations in terms of factual accuracy and depth. The model is effective at producing coherent sentences and maintaining a narrative flow, but it can easily generate content that, while readable, might be misleading or incorrect when it comes to real-world facts. This output demonstrates that while GPT-2 is a powerful tool for generating creative content, its use in contexts requiring factual precision or in-depth analysis should be carefully managed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce540cea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
